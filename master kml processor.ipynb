{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a98e38",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#scan_zip()\" data-toc-modified-id=\"scan_zip()-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>scan_zip()</a></span></li><li><span><a href=\"#parse_kml(kml)\" data-toc-modified-id=\"parse_kml(kml)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>parse_kml(kml)</a></span></li><li><span><a href=\"#habitat()\" data-toc-modified-id=\"habitat()-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>habitat()</a></span></li><li><span><a href=\"#geolocators(lat,-long,-df)\" data-toc-modified-id=\"geolocators(lat,-long,-df)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>geolocators(lat, long, df)</a></span></li><li><span><a href=\"#reverse-geocoding\" data-toc-modified-id=\"reverse-geocoding-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>reverse geocoding</a></span></li><li><span><a href=\"#parse_file()\" data-toc-modified-id=\"parse_file()-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>parse_file()</a></span></li><li><span><a href=\"#Database-insertion\" data-toc-modified-id=\"Database-insertion-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Database insertion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "712d2992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile  \n",
    "import zipfile\n",
    "import sys  #sys.exit to stop program when conditions not met\n",
    "import os  \n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import requests  #Used for sunrise sunset api\n",
    "import json  \n",
    "from bs4 import BeautifulSoup as Soup  \n",
    "import geopandas as gpd  \n",
    "from shapely.geometry import Point  \n",
    "from shapely import wkt  \n",
    "from geopy.geocoders import Nominatim \n",
    "import shutil  \n",
    "import pymongo\n",
    "#cd C:\\Program Files\\MongoDB\\Server\\5.0\\bin\n",
    "#mongod\n",
    "#mongo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c1843e",
   "metadata": {},
   "source": [
    "# scan_zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86feabe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scan through directory to find zip file\n",
    "#Scan through zip file to ensure only .wav and .kml files are present\n",
    "#If other files present then code exited\n",
    "def scan_zip():\n",
    "    for i in os.listdir():  #looping through directory to find zip file\n",
    "        if '.zip' in i:\n",
    "            zips = [i]\n",
    "\n",
    "    if len(zips) == 1:  #will only proceed if 1 zip file found\n",
    "        if (zipfile.is_zipfile(zips[0])) == True:\n",
    "            print('One zip file found, will continue to process.')\n",
    "        else:\n",
    "            sys.exit('zip file corrupted.')  #if 0 or more than 1 zip found processing stopped\n",
    "    if len(zips) < 1:\n",
    "        sys.exit('No zip file found, not able to process.')\n",
    "    if len(zips) > 1:\n",
    "        sys.exit('More than one zip file found, not able to process.')\n",
    "\n",
    "    ziplist = zipfile.ZipFile(zips[0]).namelist()  #Looking through zip file to ensure only approriate files found\n",
    "    #should be at least 1 wav file and only 1 kml file and no other files\n",
    "    wav_count = 0\n",
    "    kml_count = 0\n",
    "    other_count = 0\n",
    "    other_file = []\n",
    "    for i in ziplist:\n",
    "        if '.wav' in i:\n",
    "            wav_count += 1\n",
    "        if '.kml' in i:\n",
    "            kml_count += 1\n",
    "        if '.wav' not in i:\n",
    "            if '.kml' not in i:\n",
    "                other_file.append(i)\n",
    "                other_file += 1\n",
    "    if wav_count < 1:\n",
    "        sys.exit('Error, no .wav files found')\n",
    "    if kml_count > 1:\n",
    "        sys.exit('Error, too many .kml files found, should only be 1.')\n",
    "    if kml_count < 1:\n",
    "        sys.exit('Error, no .kml file found, should be 1.')\n",
    "    if kml_count == 1:\n",
    "        if wav_count >1:\n",
    "            print('1 .kml file found,', 'and', wav_count, '.wav files found. Able to process files.')\n",
    "            for i in os.listdir():\n",
    "                if '.zip' in i:\n",
    "                    zip_file = [os.path.abspath(i)]\n",
    "    with ZipFile(zip_file[0], 'r') as zipObj:  #Unzipping and identifying kml file path\n",
    "        listOfFileNames = zipObj.namelist()\n",
    "        for fileName in listOfFileNames:\n",
    "            if fileName.endswith('.kml'):\n",
    "                zipObj.extract(fileName)\n",
    "                fn = fileName\n",
    "    destination = 'C:\\\\Users\\\\matta\\\\OneDrive\\\\Documents\\\\Python\\\\Bat Database\\\\LT_storage'\n",
    "    if zips[0] in os.listdir(destination):\n",
    "        print('File already uploaded to database.')\n",
    "        process_opt = {1 : 'Yes', 2 : 'No'}\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                opt = int(input('Do you want to continue processing to replace existing file? 1 for yes, 2 for no and exit'))\n",
    "                if opt in process_opt.keys():\n",
    "                    if opt == 1:\n",
    "                        print('Original file in database will be replaced.')\n",
    "                        os.remove(destination + '\\\\' + zips[0])\n",
    "                        return(fn)  #kml file path\n",
    "                        break\n",
    "                    else:\n",
    "                        if opt == 2:\n",
    "                            print('Upload will not continue.')\n",
    "                            return('xxx')\n",
    "                            break\n",
    "            except:\n",
    "                print('Invalid input, select either 1 for yes to replace or 2 for no and exit.')\n",
    "    else:\n",
    "        return(fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0d5381",
   "metadata": {},
   "source": [
    "# parse_kml(kml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "823373bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing data in kml to place in dataframe or json for insertion into database\n",
    "def parse_kml(kml):\n",
    "    f = open(kml, 'r')  #open kml file from path\n",
    "    s = Soup(f, 'xml')  #Creating beautiful soup object\n",
    "    placemark = s.find_all(\"Placemark\")  #parsing different sections of kml\n",
    "    names = []  #will be used for list of bat names detected\n",
    "    coordinatesbats = []  #will be used for coordinates for each wav file\n",
    "    for i in range(len(placemark)-1):  #last placemark in KML is a list of all locations logged in session so it is removed from loop\n",
    "        names.append(placemark[i].find('name').text)\n",
    "        coordinatesbats.append(placemark[i].find(\"coordinates\").text)\n",
    "    coords = s.find('LineString').find('coordinates').text\n",
    "    coordinates = []  #coordinates of path walked for survey\n",
    "    for i in coords.split(' '):  #splitting out lat, long, elevation \n",
    "        coordinates.append(list(i.split(',')))\n",
    "    #extracting divice used, removed .text.replace()\n",
    "    detector = placemark[0].find('ExtendedData').text.replace('\\n', ' ').strip().split('  ')[1].strip()  \n",
    "    df = pd.DataFrame()  #making dataframe to place all metadata extracted from kml for each detection\n",
    "    df['names'] = names  #file names\n",
    "    df['coordinates'] = coordinatesbats  #coordinates of each detection\n",
    "    df[['id', 'date', 'time']]  = df['names'].str.split('_', expand=True)  #bat id, date and time of detection\n",
    "    df[['long', 'lat', 'elevation']] = df['coordinates'].str.split(',', expand=True)  #Lat, long, elevation of each detection\n",
    "    df = df.drop(columns = 'coordinates')  #drop coordinated column now that it has been parsed out\n",
    "    bats = s.find_all('Icon')  #Identification of bat or each wav file\n",
    "    species = []\n",
    "    for i in range(len(bats)-1):  #finding names of all bat potential ids\n",
    "        x = bats[i].find('href').text  #extracting potential bat name\n",
    "        y = x.split('_')[1]  \n",
    "        species.append(y.split('.')[0])  #extracting actual bat name\n",
    "    df = df[df['id'].isin(species)]  #making sure all id wav files found in possible bat id file\n",
    "    table = pd.DataFrame(df.id.value_counts()).T  #new dataframe for aggregated data\n",
    "    #averaging out all lat, long, elev as a generalize decription of location\n",
    "    table[['latitude', 'longitude', 'elevation']] = np.mean(df.lat.astype(float)), np.mean(df.long.astype(float)), np.mean(df.elevation.astype(float))\n",
    "    detect = list(df.id.unique())  #these will be used as column lables for bat detection total counts\n",
    "    table['total_detections'] = table[detect].sum(axis=1)  #total detections of bats, sum of all detections\n",
    "    df['datetime'] = pd.to_datetime((df.date + df.time), format='%Y%m%d%H%M%S', errors='ignore')  #changing datatype\n",
    "    \n",
    "    table['1st_detection_time'] = min(df.datetime)  #Datetime of first recording\n",
    "    table['1st_detection_time'] = str(table['1st_detection_time']).split('\\n')[0].split(' ')[4]\n",
    "    table['last_detection_time'] = max(df.datetime) #Datetime of last recoding\n",
    "    table['last_detection_time'] = str(table['last_detection_time']).split('\\n')[0].split(' ')[4]\n",
    "    table['recording_duration'] = max(df.datetime) - min(df.datetime)  #difference in time between first and last recodings\n",
    "    table['recording_duration'] = str(table.recording_duration).split('\\n')[0].split(' ')[5]\n",
    "    table['date'] = df.date[0]\n",
    "    \n",
    "    lat = table.latitude.values[0]\n",
    "    long = table.longitude.values[0]\n",
    "    date = pd.to_datetime(table['date']).dt.strftime('%Y-%m-%d').values[0]\n",
    "    key = 'b1f36a90a5b0448888404882991efde3'\n",
    "    query = 'https://api.ipgeolocation.io/astronomy?'f'apiKey={key}&lat={lat}&long={long}&date={date}'  #API queiry for sunrise/sunset\n",
    "    a = requests.get(query)\n",
    "    a = json.loads(a.text)\n",
    "    table['sunrise_time'] = a['sunrise']\n",
    "    table['sunset_time'] = a['sunset']\n",
    "    table['detector'] = detector\n",
    "    f.close()\n",
    "    os.remove(kml)  #Deleting unzipped kml\n",
    "    os.rmdir(kml.split('/')[0])  #deleting unzipped kml directory \n",
    "    for i in os.listdir():\n",
    "        if '.zip' in i:\n",
    "            zip_file = [os.path.abspath(i)]\n",
    "    source = zip_file[0]  #Path of raw data zipfile\n",
    "    #Destination of zipfile for long term storage\n",
    "    destination = 'C:\\\\Users\\\\matta\\\\OneDrive\\\\Documents\\\\Python\\\\Bat Database\\\\LT_storage'\n",
    "    dest = shutil.move(source, destination)  #moving file to long term storage\n",
    "    table['path'] = dest  #saving path of raw data in lont term storage\n",
    "    return(table)  #returns summary 1 row dataframe of data collected in survey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5531c8d",
   "metadata": {},
   "source": [
    "# habitat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8184ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asks user basic habitat questions that will be entered into the dataframe\n",
    "def habitat():\n",
    "    #Wetland\n",
    "    wetland_opt = {0 : 'Upland', 1 : 'Wetland'}\n",
    "    while True:\n",
    "        try:\n",
    "            wtl = int(input('Did the area surveyed contain wetland?: 1 = yes, 0 = no'))\n",
    "            if (wtl in wetland_opt.keys()):\n",
    "                print(wetland_opt[wtl])\n",
    "                wetland = wetland_opt[wtl]\n",
    "                break\n",
    "            else:\n",
    "                print('Invalid input, select either 1 for wetland present or 0 for no wetlands') \n",
    "        except:\n",
    "            print('Invalid input, select either 1 for wetland present or 0 for no wetlands')\n",
    "\n",
    "    #Development\n",
    "    dvlp_opt = {3 : 'Urban', 2 : 'Suburban', 1 : 'Rural', 0 : 'Undeveloped'}\n",
    "    while True:\n",
    "        try:\n",
    "            dvlp = int(input('How developed was the area surveyed?: 3 = Urban, 2 = Suburban, 1 = Rural, 0 = Undeveloped'))\n",
    "            if (dvlp in dvlp_opt.keys()):\n",
    "                print(dvlp_opt[dvlp])\n",
    "                development = dvlp_opt[dvlp]\n",
    "                break\n",
    "            else:\n",
    "                print(\"Invalid input: select 3 = Urban, 2 = Suburban, 1 = Rural, 0 = Undeveloped\") \n",
    "        except:\n",
    "            print(\"Invalid input: select 3 = Urban, 2 = Suburban, 1 = Rural, 0 = Undeveloped\")\n",
    "\n",
    "    #Vegetation\n",
    "    veg_opt = {1 : 'desert scrub', 2 : 'grassland', 3 : 'shrubland', 4 : 'open woodland', 5 : 'forest', \n",
    "               6 : 'urban/suburban park or greenspace', 7 : 'predominantly buildings/cement', 8 : 'neighborhood'}\n",
    "    while True:\n",
    "        try:\n",
    "            print('What type of vegetation/habitat is present?: 1 : desert scrub, 2 : grassland, 3 : shrubland,', \n",
    "                            '4 : open woodland, 5 : forest, 6 : urban/suburban park or greenspace,'\n",
    "                            '7 : predominantly buildings/cement, 8 : neighborhood')\n",
    "            veg = int(input())\n",
    "            if (veg in veg_opt.keys()):\n",
    "                print(veg_opt[veg])\n",
    "                vegetation = veg_opt[veg]\n",
    "                break\n",
    "            else:\n",
    "                print('Invalid input: select 1 : desert scrub, 2 : grassland, 3 : shrubland,', \n",
    "                            '4 : open woodland, 5 : forest, 6 : urban/suburban park or greenspace,'\n",
    "                            '7 : predominantly buildings/cement, 8 : neighborhood') \n",
    "        except:\n",
    "            print('Invalid input: select 1 : desert scrub, 2 : grassland, 3 : shrubland, 4 : open woodland, 5 : forest, 6 : urban/suburban park or greenspace, 7 : agriculture, 8 : predominantly buildings/cement, 9 : neighborhood')\n",
    "        \n",
    "    #Dataframe of output\n",
    "    hdf = pd.DataFrame()\n",
    "    hdf['id'] = [wetland, development, vegetation]\n",
    "    hdf = hdf.T\n",
    "    hdf.columns = 'Wetland_status', 'Development', 'Vegetation'\n",
    "    return(hdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e51958b",
   "metadata": {},
   "source": [
    "# geolocators(lat, long, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f178fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPA North American Ecoregions Level 3\n",
    "NA3 = pd.read_csv('ecoregions3.csv') #Load Pandas dataframe\n",
    "NA3['geometry'] = NA3['geometry'].apply(wkt.loads) #Convert geometry for geopandas\n",
    "NA3 = gpd.GeoDataFrame(NA3) #Convert pandas dataframe to geopandas dataframe\n",
    "\n",
    "#Create function to obtain epa ecoregions 1, 2, and 3\n",
    "#Uses single set of lat and long for output\n",
    "def get_eco(lat, long):\n",
    "  point = Point(long, lat)\n",
    "  for i in range(0, len(NA3)):\n",
    "    if point.within(NA3[\"geometry\"][i])==True:\n",
    "      loc = [NA3['NA_L1KEY'][i],  NA3['NA_L2KEY'][i],  NA3['NA_L3KEY'][i]]\n",
    "      return(loc)\n",
    "\n",
    "#Create function that uses get_eco for entire dataframe.\n",
    "def get_ecoregions(lat, long, df):  #df is dataframe function will be used on\n",
    "  ecos = []\n",
    "  for i in range(0, len(df)):\n",
    "    ecos.append(get_eco(lat[i], long[i]))\n",
    "  df[['Level_1', 'Level_2', 'Level_3']] = ecos\n",
    "\n",
    "########## \n",
    "#EPA United States Ecoregions Level 4\n",
    "US4 = pd.read_csv('ecoregions4.csv') #Load Pandas dataframe\n",
    "US4['geometry'] = US4['geometry'].apply(wkt.loads) #Convert geometry for geopandas\n",
    "US4 = gpd.GeoDataFrame(US4) #Convert pandas dataframe to geopandas dataframe\n",
    "\n",
    "#Create function to obtain epa ecoregion 4\n",
    "#Uses single set of lat and long for output\n",
    "def get_eco4(lat, long):\n",
    "  point = Point(long, lat)\n",
    "  for i in range(0, len(US4)):\n",
    "    if point.within(US4[\"geometry\"][i])==True:\n",
    "      loc = [US4['L1_KEY'][i], US4['L2_KEY'][i], US4['L3_KEY'][i], US4['L4_KEY'][i]]\n",
    "      return(loc)\n",
    "\n",
    "#Create function that uses get_eco for entire dataframe.\n",
    "def get_ecoregions4(lat, long, df):  #df is dataframe function will be used on\n",
    "  ecos = []\n",
    "  for i in range(0, len(df)):\n",
    "    ecos.append(get_eco4(lat[i], long[i]))\n",
    "  df[['Level_4', 'Level_3', 'Level_2', 'Level_1']] = ecos\n",
    "\n",
    "###########\n",
    "#WWF ecoregions\n",
    "wwf = pd.read_csv('wwfecos.csv') #Load Pandas dataframe\n",
    "wwf['geometry'] = wwf['geometry'].apply(wkt.loads) #Convert geometry for geopandas\n",
    "wwf = gpd.GeoDataFrame(wwf) #Convert pandas dataframe to geopandas dataframe\n",
    "\n",
    "#Create function to obtain epa ecoregions 1, 2, and 3\n",
    "#Uses single set of lat and long for output\n",
    "def get_wwfeco(lat, long):\n",
    "  point = Point(long, lat)\n",
    "  for i in range(0, len(wwf)):\n",
    "    if point.within(wwf[\"geometry\"][i])==True:\n",
    "      loc = [wwf['ECO_NAME'][i]]\n",
    "      return(loc)\n",
    "\n",
    "#Create function that uses get_eco for entire dataframe.\n",
    "def get_wwfecoregions(lat, long, df):  #df is dataframe function will be used on\n",
    "  ecos = []\n",
    "  for i in range(0, len(df)):\n",
    "    ecos.append(get_wwfeco(lat[i], long[i]))\n",
    "  df[['WWF_ecoregion']] = ecos\n",
    "\n",
    "###################\n",
    "#koppen_geiger regions\n",
    "kg = pd.read_csv('koppen_geiger.csv') #Load Pandas dataframe\n",
    "kg['geometry'] = kg['geometry'].apply(wkt.loads) #Convert geometry for geopandas\n",
    "kg = gpd.GeoDataFrame(kg) #Convert pandas dataframe to geopandas dataframe\n",
    "\n",
    "#Create function to obtain epa ecoregions 1, 2, and 3\n",
    "#Uses single set of lat and long for output\n",
    "def get_clim(lat, long):\n",
    "  point = Point(long, lat)\n",
    "  for i in range(0, len(kg)):\n",
    "    if point.within(kg[\"geometry\"][i])==True:\n",
    "      loc = [kg['climates_f'][i]]\n",
    "      return(loc)\n",
    "\n",
    "#Create function that uses get_eco for entire dataframe.\n",
    "def get_koppen_greiger(lat, long, df):  #df is dataframe function will be used on\n",
    "  ecos = []\n",
    "  for i in range(0, len(df)):\n",
    "    ecos.append(get_clim(lat[i], long[i]))\n",
    "  df[['koppen_geiger']] = ecos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe86f296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining all geolocators into one function\n",
    "def geolocators(lat, long, df):\n",
    "    get_koppen_greiger(lat, long, df)\n",
    "    get_wwfecoregions(lat, long, df)\n",
    "    try:\n",
    "        get_ecoregions4(lat, long, df)  \n",
    "    except:\n",
    "        pass  #pass is used here because lat, long outside of USA will produce errors\n",
    "    try:\n",
    "        get_ecoregions(lat, long, df)\n",
    "    except:\n",
    "        pass  #pass used here because lat, long outside of North America will produce errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5f420",
   "metadata": {},
   "source": [
    "Need username and password sign-in shell <br>\n",
    "Need drag and drop file uploader for zip data <br>\n",
    "Need to insert user name from sign-in into dataframe <br>\n",
    "Need to insert survey site name into dataframe <br>\n",
    "Function to insert metadata into database with path to raw data zip file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c47d79",
   "metadata": {},
   "source": [
    "# reverse geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41b6afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def location(df):\n",
    "    geolocator = Nominatim(user_agent=\"geoapi\")\n",
    "    coords = str(df.latitude[0]) + ', ' + str(df.longitude[0])\n",
    "    location = geolocator.reverse(coords)\n",
    "    for k, v in location.raw['address'].items():\n",
    "        df[k] = v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed912bb4",
   "metadata": {},
   "source": [
    "# parse_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b8e26fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining all functions into one function\n",
    "def process_file():\n",
    "    fn = scan_zip()\n",
    "    if fn == 'xxx':\n",
    "        sys.exit('File already uploaded')\n",
    "    else:\n",
    "        x = parse_kml(fn)\n",
    "        geolocators(x.latitude, x.longitude, x)\n",
    "        location(x)\n",
    "        h = habitat()\n",
    "        fdf = pd.concat([x, h], axis = 1, join = 'outer')\n",
    "    return(fdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75db866c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One zip file found, will continue to process.\n",
      "1 .kml file found, and 139 .wav files found. Able to process files.\n",
      "Did the area surveyed contain wetland?: 1 = yes, 0 = no0\n",
      "Upland\n",
      "How developed was the area surveyed?: 3 = Urban, 2 = Suburban, 1 = Rural, 0 = Undeveloped1\n",
      "Rural\n",
      "What type of vegetation/habitat is present?: 1 : desert scrub, 2 : grassland, 3 : shrubland, 4 : open woodland, 5 : forest, 6 : urban/suburban park or greenspace,7 : predominantly buildings/cement, 8 : neighborhood\n",
      "1\n",
      "desert scrub\n"
     ]
    }
   ],
   "source": [
    "df = process_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48670bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NoID</th>\n",
       "      <th>DICALB</th>\n",
       "      <th>MOLRUF</th>\n",
       "      <th>CYNMEX</th>\n",
       "      <th>MOLMOL</th>\n",
       "      <th>MOLSIN</th>\n",
       "      <th>MYOCAL</th>\n",
       "      <th>SACBIL</th>\n",
       "      <th>EUMPER</th>\n",
       "      <th>PARHES</th>\n",
       "      <th>...</th>\n",
       "      <th>village</th>\n",
       "      <th>municipality</th>\n",
       "      <th>state</th>\n",
       "      <th>ISO3166-2-lvl4</th>\n",
       "      <th>postcode</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>Wetland_status</th>\n",
       "      <th>Development</th>\n",
       "      <th>Vegetation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>92</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Tulum</td>\n",
       "      <td>Solidaridad</td>\n",
       "      <td>Quintana Roo</td>\n",
       "      <td>MX-ROO</td>\n",
       "      <td>77774</td>\n",
       "      <td>México</td>\n",
       "      <td>mx</td>\n",
       "      <td>Upland</td>\n",
       "      <td>Rural</td>\n",
       "      <td>desert scrub</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    NoID  DICALB  MOLRUF  CYNMEX  MOLMOL  MOLSIN  MYOCAL  SACBIL  EUMPER  \\\n",
       "id    92      14      13       4       4       3       3       2       1   \n",
       "\n",
       "    PARHES  ...  village  municipality         state  ISO3166-2-lvl4  \\\n",
       "id       1  ...    Tulum   Solidaridad  Quintana Roo          MX-ROO   \n",
       "\n",
       "    postcode country country_code Wetland_status Development    Vegetation  \n",
       "id     77774  México           mx         Upland       Rural  desert scrub  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ad12a1",
   "metadata": {},
   "source": [
    "# Database insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bec1d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "mydb = myclient[\"batdatabase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c99f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mycol = mydb[\"batsurveys\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8c884a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43abfa90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'NoID': 92,\n",
       "  'DICALB': 14,\n",
       "  'MOLRUF': 13,\n",
       "  'CYNMEX': 4,\n",
       "  'MOLMOL': 4,\n",
       "  'MOLSIN': 3,\n",
       "  'MYOCAL': 3,\n",
       "  'SACBIL': 2,\n",
       "  'EUMPER': 1,\n",
       "  'PARHES': 1,\n",
       "  'TADBRA': 1,\n",
       "  'latitude': 20.254680195652174,\n",
       "  'longitude': -87.40469659782609,\n",
       "  'elevation': -4.688760717742896,\n",
       "  'total_detections': 138,\n",
       "  '1st_detection_time': '21:10:55',\n",
       "  'last_detection_time': '21:42:56',\n",
       "  'recording_duration': '00:32:01',\n",
       "  'date': '20220629',\n",
       "  'sunrise_time': '06:12',\n",
       "  'sunset_time': '19:33',\n",
       "  'detector': 'Echo Meter Touch 2 Standard Android',\n",
       "  'path': 'C:\\\\Users\\\\matta\\\\OneDrive\\\\Documents\\\\Python\\\\Bat Database\\\\LT_storage\\\\Session_20220629_211054.zip',\n",
       "  'koppen_geiger': 'AW',\n",
       "  'WWF_ecoregion': 'Yucatán moist forests',\n",
       "  'Level_1': '15  TROPICAL WET FORESTS',\n",
       "  'Level_2': '15.2  PLAIN AND HILLS OF THE YUCATAN PENINSULA',\n",
       "  'Level_3': '15.2.2  Plain with Medium and High Semi-Evergreen Tropical Forest',\n",
       "  'leisure': 'Dreams Tulum Resort & spa',\n",
       "  'road': 'Avenida Tulúm',\n",
       "  'village': 'Tulum',\n",
       "  'municipality': 'Solidaridad',\n",
       "  'state': 'Quintana Roo',\n",
       "  'ISO3166-2-lvl4': 'MX-ROO',\n",
       "  'postcode': '77774',\n",
       "  'country': 'México',\n",
       "  'country_code': 'mx',\n",
       "  'Wetland_status': 'Upland',\n",
       "  'Development': 'Rural',\n",
       "  'Vegetation': 'desert scrub'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0aa45390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x22c41f8ace0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycol.insert_one({\"index\" : \"bat_survey\",\"data\" : data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7aee1977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'batdatabase'), 'batsurveys')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99244e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('636449ced762aae0a80f61e7'),\n",
       " 'index': 'bat_survey',\n",
       " 'data': [{'NoID': 92,\n",
       "   'DICALB': 14,\n",
       "   'MOLRUF': 13,\n",
       "   'CYNMEX': 4,\n",
       "   'MOLMOL': 4,\n",
       "   'MOLSIN': 3,\n",
       "   'MYOCAL': 3,\n",
       "   'SACBIL': 2,\n",
       "   'EUMPER': 1,\n",
       "   'PARHES': 1,\n",
       "   'TADBRA': 1,\n",
       "   'latitude': 20.254680195652174,\n",
       "   'longitude': -87.40469659782609,\n",
       "   'elevation': -4.688760717742896,\n",
       "   'total_detections': 138,\n",
       "   '1st_detection_time': '21:10:55',\n",
       "   'last_detection_time': '21:42:56',\n",
       "   'recording_duration': '00:32:01',\n",
       "   'date': '20220629',\n",
       "   'sunrise_time': '06:12',\n",
       "   'sunset_time': '19:33',\n",
       "   'detector': 'Echo Meter Touch 2 Standard Android',\n",
       "   'path': 'C:\\\\Users\\\\matta\\\\OneDrive\\\\Documents\\\\Python\\\\Bat Database\\\\LT_storage\\\\Session_20220629_211054.zip',\n",
       "   'koppen_geiger': 'AW',\n",
       "   'WWF_ecoregion': 'Yucatán moist forests',\n",
       "   'Level_1': '15  TROPICAL WET FORESTS',\n",
       "   'Level_2': '15.2  PLAIN AND HILLS OF THE YUCATAN PENINSULA',\n",
       "   'Level_3': '15.2.2  Plain with Medium and High Semi-Evergreen Tropical Forest',\n",
       "   'leisure': 'Dreams Tulum Resort & spa',\n",
       "   'road': 'Avenida Tulúm',\n",
       "   'village': 'Tulum',\n",
       "   'municipality': 'Solidaridad',\n",
       "   'state': 'Quintana Roo',\n",
       "   'ISO3166-2-lvl4': 'MX-ROO',\n",
       "   'postcode': '77774',\n",
       "   'country': 'México',\n",
       "   'country_code': 'mx',\n",
       "   'Wetland_status': 'Upland',\n",
       "   'Development': 'Rural',\n",
       "   'Vegetation': 'desert scrub'}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycol.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f91a6af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('636449ced762aae0a80f61e7'), 'index': 'bat_survey', 'data': [{'NoID': 92, 'DICALB': 14, 'MOLRUF': 13, 'CYNMEX': 4, 'MOLMOL': 4, 'MOLSIN': 3, 'MYOCAL': 3, 'SACBIL': 2, 'EUMPER': 1, 'PARHES': 1, 'TADBRA': 1, 'latitude': 20.254680195652174, 'longitude': -87.40469659782609, 'elevation': -4.688760717742896, 'total_detections': 138, '1st_detection_time': '21:10:55', 'last_detection_time': '21:42:56', 'recording_duration': '00:32:01', 'date': '20220629', 'sunrise_time': '06:12', 'sunset_time': '19:33', 'detector': 'Echo Meter Touch 2 Standard Android', 'path': 'C:\\\\Users\\\\matta\\\\OneDrive\\\\Documents\\\\Python\\\\Bat Database\\\\LT_storage\\\\Session_20220629_211054.zip', 'koppen_geiger': 'AW', 'WWF_ecoregion': 'Yucatán moist forests', 'Level_1': '15  TROPICAL WET FORESTS', 'Level_2': '15.2  PLAIN AND HILLS OF THE YUCATAN PENINSULA', 'Level_3': '15.2.2  Plain with Medium and High Semi-Evergreen Tropical Forest', 'leisure': 'Dreams Tulum Resort & spa', 'road': 'Avenida Tulúm', 'village': 'Tulum', 'municipality': 'Solidaridad', 'state': 'Quintana Roo', 'ISO3166-2-lvl4': 'MX-ROO', 'postcode': '77774', 'country': 'México', 'country_code': 'mx', 'Wetland_status': 'Upland', 'Development': 'Rural', 'Vegetation': 'desert scrub'}]}\n",
      "{'_id': ObjectId('63644a01d762aae0a80f61e9'), 'index': 'bat_survey', 'data': [{'NoID': 92, 'DICALB': 14, 'MOLRUF': 13, 'CYNMEX': 4, 'MOLMOL': 4, 'MOLSIN': 3, 'MYOCAL': 3, 'SACBIL': 2, 'EUMPER': 1, 'PARHES': 1, 'TADBRA': 1, 'latitude': 20.254680195652174, 'longitude': -87.40469659782609, 'elevation': -4.688760717742896, 'total_detections': 138, '1st_detection_time': '21:10:55', 'last_detection_time': '21:42:56', 'recording_duration': '00:32:01', 'date': '20220629', 'sunrise_time': '06:12', 'sunset_time': '19:33', 'detector': 'Echo Meter Touch 2 Standard Android', 'path': 'C:\\\\Users\\\\matta\\\\OneDrive\\\\Documents\\\\Python\\\\Bat Database\\\\LT_storage\\\\Session_20220629_211054.zip', 'koppen_geiger': 'AW', 'WWF_ecoregion': 'Yucatán moist forests', 'Level_1': '15  TROPICAL WET FORESTS', 'Level_2': '15.2  PLAIN AND HILLS OF THE YUCATAN PENINSULA', 'Level_3': '15.2.2  Plain with Medium and High Semi-Evergreen Tropical Forest', 'leisure': 'Dreams Tulum Resort & spa', 'road': 'Avenida Tulúm', 'village': 'Tulum', 'municipality': 'Solidaridad', 'state': 'Quintana Roo', 'ISO3166-2-lvl4': 'MX-ROO', 'postcode': '77774', 'country': 'México', 'country_code': 'mx', 'Wetland_status': 'Upland', 'Development': 'Rural', 'Vegetation': 'desert scrub'}]}\n"
     ]
    }
   ],
   "source": [
    "for i in mycol.find():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9037c62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
